{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06fb6402",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "This notebook is created to practice tensorflow library basics. Since I do know pytorch in a very good level, to create this notes, I used the beginning chapters of expert tutorials. You can find the tutorials from the website of [tensorflow](https://www.tensorflow.org/tutorials). After the beginning chapters of the tutorials were finished, I used tensorflow [guide](https://www.tensorflow.org/guide)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad57f1a2",
   "metadata": {},
   "source": [
    "## Tensorflow Basics\n",
    "TensorFlow is an end-to-end platform for machine learning. It supports the following:\n",
    "\n",
    "- Multidimensional-array based numeric computation (similar to NumPy)\n",
    "- GPU and distributed processing\n",
    "- Automatic differentiation\n",
    "- Model construction, training, and export\n",
    "and more...\n",
    "\n",
    "Tensorflow operates on multidimensional arrays or _tensors_ represented as **tf.Tensor** objects. The most important attributes of a __tf.Tensor__ is its _shape_ and _dtype_:\n",
    "- __Tensor.shape:__ tells you the size of the tensor along each of its axes\n",
    "- __Tensor.dtype:__ tels you the type of the all elements in the tensor\n",
    "\n",
    "You can use standart mathematical operations on tensors, as well as many operations specialized for machine learning. Running to many parallel computation on CPU can be really slow. Hence, tensorflow is designed for supporting GPU computations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe624025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor x -> [[1 2 3]\n",
      " [4 5 6]]\n",
      "Shape of x -> (2, 3)\n",
      "Dtype of x -> <dtype: 'int32'>\n",
      "\n",
      "Basic Operations\n",
      "Square:\n",
      "tf.Tensor(\n",
      "[[ 1  4  9]\n",
      " [16 25 36]], shape=(2, 3), dtype=int32)\n",
      "\n",
      " Multiplication (Matrix):\n",
      "tf.Tensor(\n",
      "[[14 32]\n",
      " [32 77]], shape=(2, 2), dtype=int32)\n",
      "\n",
      " Softmax operation:\n",
      "tf.Tensor(\n",
      "[[0.09003057 0.24472848 0.66524094]\n",
      " [0.09003057 0.24472848 0.66524094]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# tensorflow tensor basics\n",
    "\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "print(f\"Tensor x -> {x}\")\n",
    "print(f\"Shape of x -> {x.shape}\")\n",
    "print(f\"Dtype of x -> {x.dtype}\")\n",
    "\n",
    "print(\"\\nBasic Operations\")\n",
    "print(\"Square:\")\n",
    "print(x * x)\n",
    "print(\"\\n Multiplication (Matrix):\")\n",
    "print(x @ tf.transpose(x))\n",
    "x = tf.cast(x, tf.float32)\n",
    "print(\"\\n Softmax operation:\")\n",
    "print(tf.nn.softmax(x, axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391c64a8",
   "metadata": {},
   "source": [
    "### Tensorflow Variables\n",
    "Normal __tf.Tensor__ objects are immutable. To store weights (or mutable state) in TensorFlow, use __tf.Variable__. Everything is similar for __tf.Variable__ and __tf.Tensor__ objects except mutability.\n",
    "\n",
    "### Autmatic differentiation\n",
    "Gradient descent and related algorithms are a cornerstone of modern machine learning. To enable this, TensorFlow implements automatic differention (autodiff), which uses calculus to compute gradients. Typically, you'll use this to calculate the gradient of the model's error or loss with respect to its weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7073a0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable:\n",
      "<tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>\n",
      "\n",
      "Variable after assignment:\n",
      "<tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>\n",
      "\n",
      "Variable after addition:\n",
      "<tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([4., 4., 4.], dtype=float32)>\n",
      "\n",
      "Function without gradient:\n",
      "tf.Tensor(-2.0, shape=(), dtype=float32)\n",
      "\n",
      "Function with gradient\n",
      "tf.Tensor(-2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(4.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# using tensorflow variables\n",
    "var = tf.Variable([0.0, 0.0, 0.0])\n",
    "print(\"Variable:\")\n",
    "print(var)\n",
    "var.assign([1, 2, 3])\n",
    "print(\"\\nVariable after assignment:\")\n",
    "print(var)\n",
    "var.assign_add([3, 2, 1])\n",
    "print(\"\\nVariable after addition:\")\n",
    "print(var)\n",
    "\n",
    "# using automatic differentiation\n",
    "x = tf.Variable(1.0)\n",
    "\n",
    "def f(x: tf.Variable):\n",
    "    return x**2 + 2*x - 5\n",
    "\n",
    "print(\"\\nFunction without gradient:\")\n",
    "print(f(x))\n",
    "print(\"\\nFunction with gradient\")\n",
    "with tf.GradientTape() as tape:\n",
    "    y = f(x)\n",
    "\n",
    "g_x = tape.gradient(y ,x) # g(x) = dy/dx\n",
    "print(f(x))\n",
    "print(g_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38c15a7",
   "metadata": {},
   "source": [
    "### Graphs and Functions \n",
    "While you can use TensorFlow interactively like any Python library, TensorFlow also provides tools for:\n",
    "\n",
    "- __Performance optimization:__ to speed up training and inference.\n",
    "- __Export:__ so you can save your model when it's done training.\n",
    "\n",
    "These requires that you use __tf.Function__ to separate your pure-Tensorflow code from Python.\n",
    "\n",
    "The first time you run the __tf.function__, although it executes in Python, it captures a complete, optimized graph representing the TensorFlow computations done within the function.\n",
    "\n",
    "On subsequent calls TensorFlow only executes the optimized graph, skipping any non-TensorFlow steps. Below, note that my_func doesn't print tracing since print is a Python function, not a TensorFlow function.\n",
    "\n",
    "A graph may not be reusable for inputs with a different signature (shape and dtype), so a new graph is generated instead. These captured graphs provide two benefits:\n",
    "\n",
    "- In many cases they provide a significant speedup in execution.\n",
    "- You can export these graphs, using tf.saved_model, to run on other systems like a server or a mobile device, no Python installation required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab97bea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing.\n",
      "tf.Tensor(6, shape=(), dtype=int32) \n",
      "\n",
      "tf.Tensor(27, shape=(), dtype=int32) \n",
      "\n",
      "Tracing.\n",
      "tf.Tensor(28.000002, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# tf.function implementation\n",
    "@tf.function\n",
    "def my_func(x):\n",
    "  print('Tracing.')\n",
    "  return tf.reduce_sum(x)\n",
    "\n",
    "# first call to generate graph\n",
    "x = tf.constant([1, 2, 3])\n",
    "print(my_func(x), \"\\n\")\n",
    "\n",
    "# second call (ignoring the non-Tensorflow steps)\n",
    "x = tf.constant([10, 9, 8])\n",
    "print(my_func(x), \"\\n\")\n",
    "\n",
    "# generating a new graph for different dtype\n",
    "x = tf.constant([10.1, 9.8, 8.1], dtype=tf.float32)\n",
    "print(my_func(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f88bc0d",
   "metadata": {},
   "source": [
    "### Modules, Layers and Models\n",
    "__tf.Module__ is a class for managing your __tf.Variable__ objects, and the __tf.function__ objects that operate on them. The __tf.Module__ class is necessary to support two significant features:\n",
    "\n",
    "1. You can save and restore the values of your variables using __tf.train.Checkpoint__. This is useful during training as it is quick to save and restore a model's state.\n",
    "2. You can import and export the __tf.Variable__ values and the __tf.function__ graphs using __tf.saved_model__. This allows you to run your model independently of the Python program that created it.\n",
    "\n",
    "Here is a complete example exporting a simple tf.Module object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f1cd3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module output:\n",
      "tf.Tensor([3 6 9], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "class MyModule(tf.Module):\n",
    "  def __init__(self, value):\n",
    "    self.weight = tf.Variable(value)\n",
    "\n",
    "  @tf.function\n",
    "  def multiply(self, x):\n",
    "    return x * self.weight\n",
    "\n",
    "mod = MyModule(3)\n",
    "print(\"Module output:\")\n",
    "print(mod.multiply(tf.constant([1, 2, 3])))\n",
    "\n",
    "# For saving the module\n",
    "# save_path = './saved'\n",
    "# tf.saved_model.save(mod, save_path)\n",
    "\n",
    "# For loading the module\n",
    "# reloaded = tf.saved_model.load(save_path)\n",
    "# reloaded.multiply(tf.constant([1, 2, 3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
